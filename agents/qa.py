from langchain_core.prompts import ChatPromptTemplate
from core.llm_factory import get_chat_model
from core.state import ProjectState
import os

# UÅ¼ywamy modelu REASONING (Llama 70B z Vast.ai) - najlepszy audytor
llm = get_chat_model(os.getenv("MODEL_REASONING", "llama3.3:70b"), temperature=0.1)

QA_SYSTEM_PROMPT = """
JesteÅ› QA Engineerem (Polyglot).
Twoim zadaniem jest ocena kodu i znalezienie bÅ‚Ä™dÃ³w.

ZASADY:
1. SprawdÅº czy kod jest kompletny.
2. SprawdÅº importy i logikÄ™.
3. JeÅ›li kod wyglÄ…da poprawnie -> Odpisz 'APPROVED'.
4. JeÅ›li sÄ… bÅ‚Ä™dy -> Odpisz 'REJECTED: <krÃ³tki opis co poprawiÄ‡>'.
"""

def qa_node(state: ProjectState) -> ProjectState:
    print("\nğŸ•µï¸â€â™‚ï¸ QA: Rozpoczynam audyt kodu (Llama 70B)...")
    code_dict = state.get("generated_code", {})
    
    if not code_dict:
        return {"qa_status": "REJECTED", "qa_feedback": "Brak kodu!", "logs": ["QA: Pusto"]}

    # 1. AUTO-CHECK (Tylko dla Pythona - wyÅ‚apuje bÅ‚Ä™dy skÅ‚adni od razu)
    for filename, content in code_dict.items():
        if filename.endswith(".py"):
            try:
                compile(content, filename, 'exec')
            except SyntaxError as e:
                error_msg = f"BÅÄ„D SKÅADNI (Python) w {filename}: {e}"
                print(f"ğŸ•µï¸â€â™‚ï¸ QA (Auto-Check): âŒ {error_msg}")
                return {
                    "qa_status": "REJECTED",
                    "qa_feedback": f"Popraw bÅ‚Ä…d skÅ‚adni w {filename}: {error_msg}",
                    "iteration_count": state.get("iteration_count", 0) + 1,
                    "logs": [f"QA Auto-Reject: {filename}"]
                }

    # 2. ANALIZA AI (Logika biznesowa)
    # ÅÄ…czymy kod w jeden tekst
    full_code = "\n".join([f"--- {k} ---\n{v}" for k, v in code_dict.items()])
    
    # --- FIX NA BÅÄ„D 'Invalid variable name' ---
    # Definiujemy prompt z placeholderem {code_to_check}
    prompt = ChatPromptTemplate.from_messages([
        ("system", QA_SYSTEM_PROMPT),
        ("user", "Kod do sprawdzenia:\n{code_to_check}")
    ])
    
    print(f"ğŸ•µï¸â€â™‚ï¸ QA: AnalizujÄ™ logikÄ™ ({len(code_dict)} plikÃ³w)...")
    
    # Przekazujemy kod jako wartoÅ›Ä‡ zmiennej. 
    # DziÄ™ki temu LangChain NIE bÄ™dzie prÃ³bowaÅ‚ analizowaÄ‡ klamer wewnÄ…trz full_code.
    response = (prompt | llm).invoke({"code_to_check": full_code})
    
    status = "APPROVED" if "APPROVED" in response.content else "REJECTED"
    print(f"ğŸ•µï¸â€â™‚ï¸ QA Decyzja: {status}")
    
    return {
        "qa_status": status,
        "qa_feedback": response.content,
        "iteration_count": state.get("iteration_count", 0) + 1,
        "logs": [f"QA: {status}"]
    }
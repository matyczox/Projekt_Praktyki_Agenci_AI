from langchain_core.prompts import ChatPromptTemplate
from core.llm_factory import get_chat_model
from core.state import ProjectState
from tools.file_system import save_file
import os
import json
import re

# UÅ¼ywamy modelu KODUJÄ„CEGO zdefiniowanego w .env
llm = get_chat_model(os.getenv("MODEL_CODER", "qwen3-coder:30b"), temperature=0.2)

# --- KROK 1: PROMPT DO LISTY PLIKÃ“W ---
FILE_LIST_PROMPT = """
JesteÅ› Tech Leadem. Przeanalizuj plan architekta i wylistuj WSZYSTKIE pliki, ktÃ³re trzeba stworzyÄ‡.
ZwrÃ³Ä‡ TYLKO surowÄ… listÄ™ plikÃ³w w formacie JSON (lista stringÃ³w).
Nie dodawaj Å¼adnych komentarzy ani wstÄ™pÃ³w. Tylko czysty JSON.

PrzykÅ‚ad poprawnej odpowiedzi:
["main.py", "requirements.txt", "src/utils.py"]

Plan Architekta:
{plan}
"""

# --- KROK 2: PROMPT DO GENEROWANIA KODU ---

# Definiujemy przykÅ‚ad osobno, Å¼eby nie psuÅ‚ kopiowania w czacie
EXAMPLE_BLOCK = "```python\nprint('Hello World')\n```"

CODE_GEN_PROMPT = """
JesteÅ› Senior Python Developerem.
Twoim zadaniem jest napisaÄ‡ zawartoÅ›Ä‡ pliku: "{filename}".

PLAN ARCHITEKTA:
{plan}

UWAGI OD QA (JeÅ›li sÄ…, musisz je uwzglÄ™dniÄ‡ i poprawiÄ‡ kod):
{feedback}

WYMAGANIA:
1. ZwrÃ³Ä‡ TYLKO kod tego jednego pliku.
2. Kod musi byÄ‡ otoczony znacznikami markdown, np:
""" + EXAMPLE_BLOCK + """
3. Kod musi byÄ‡ kompletny (zawieraÄ‡ wszystkie importy).
4. Nie ucinaj kodu w poÅ‚owie.

Napisz teraz kompletny kod dla pliku: {filename}
"""

def extract_json_list(text):
    """
    Bezpieczne wyciÄ…ganie listy plikÃ³w z odpowiedzi modelu.
    Radzi sobie z blokami json i czystym tekstem.
    """
    try:
        # 1. Najpierw szukamy bloku kodu json w markdown
        match = re.search(r"```json\n(.*?)\n```", text, re.DOTALL)
        if match:
            return json.loads(match.group(1))
        
        # 2. JeÅ›li nie ma markdowna, szukamy po prostu nawiasÃ³w kwadratowych
        match = re.search(r'\[.*\]', text, re.DOTALL)
        if match:
            return json.loads(match.group())
            
        # 3. PrÃ³ba bezpoÅ›redniego parsowania
        return json.loads(text)
    except Exception:
        return []

def clean_code_content(text):
    """
    Krytyczna funkcja: WyciÄ…ga czysty kod spomiÄ™dzy znacznikÃ³w markdown.
    Ignoruje gadaninÄ™ modelu przed i po kodzie.
    """
    # Regex szukajÄ…cy treÅ›ci miÄ™dzy ``` (opcjonalnie python/bash itp) a ```
    pattern = r"```(?:\w+)?\n(.*?)```"
    match = re.search(pattern, text, re.DOTALL)
    
    if match:
        return match.group(1).strip()
    else:
        # Fallback: JeÅ›li model zapomniaÅ‚ markdowna, ale daÅ‚ kod,
        # prÃ³bujemy oczyÅ›ciÄ‡ go z popularnych zwrotÃ³w.
        clean_text = text.replace("```python", "").replace("```", "").strip()
        return clean_text

def developer_node(state: ProjectState) -> ProjectState:
    tech_stack = state.get("tech_stack", "")
    
    # Pobieramy feedback od QA (jeÅ›li to kolejna iteracja)
    qa_feedback = state.get("qa_feedback", "")
    iteration = state.get("iteration_count", 0)

    print(f"\nğŸ‘¨â€ğŸ’» Developer: Rozpoczynam pracÄ™ (Iteracja {iteration})...")
    
    if qa_feedback:
        print(f"   âš ï¸ OtrzymaÅ‚em uwagi od QA. WdraÅ¼am poprawki...")

    # 1. Generowanie listy plikÃ³w
    prompt_files = ChatPromptTemplate.from_messages([
        ("system", FILE_LIST_PROMPT.format(plan=tech_stack))
    ])
    chain_files = prompt_files | llm
    response_files = chain_files.invoke({})
    
    files_to_create = extract_json_list(response_files.content)
    
    # Zabezpieczenie przed pustÄ… listÄ…
    if not files_to_create:
        print("âš ï¸ Developer nie znalazÅ‚ listy plikÃ³w. TworzÄ™ domyÅ›lny main.py.")
        files_to_create = ["main.py"]

    print(f"ğŸ“‹ Lista zadaÅ„: {files_to_create}")
    
    generated_files = {}
    logs = []
    
    # 2. PÄ™tla generowania kodu dla kaÅ¼dego pliku
    for filename in files_to_create:
        print(f"   ğŸ”¨ PiszÄ™ kod: {filename}...")
        
        # Wstrzykujemy feedback do promptu
        prompt_code = ChatPromptTemplate.from_messages([
            ("system", CODE_GEN_PROMPT.format(
                filename=filename, 
                plan=tech_stack,
                feedback=qa_feedback if qa_feedback else "Brak uwag, to pierwsza wersja."
            ))
        ])
        
        chain_code = prompt_code | llm
        response_code = chain_code.invoke({})
        
        # WyciÄ…gamy czysty kod regexem
        code_content = clean_code_content(response_code.content)
        
        # Zapisujemy na dysk uÅ¼ywajÄ…c narzÄ™dzia
        save_msg = save_file.invoke({"filename": filename, "code_content": code_content})
        
        # Logowanie
        if "Zapisano" in save_msg:
            print(f"      ğŸ’¾ Zapisano.")
        else:
            print(f"      âŒ BÅ‚Ä…d zapisu: {save_msg}")
            
        generated_files[filename] = code_content
        logs.append(f"Utworzono/Zaktualizowano: {filename}")

    return {
        "generated_code": generated_files,
        "logs": logs
    }
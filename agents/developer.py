from langchain_core.prompts import ChatPromptTemplate
from core.llm_factory import get_chat_model
from core.state import ProjectState
from tools.file_system import save_file
import os
import json
import re

# UÅ¼ywamy modelu KODUJÄ„CEGO
llm = get_chat_model(os.getenv("MODEL_CODER", "qwen3-coder:30b"), temperature=0.2)

# --- KROK 1: EKSTRAKCJA LISTY PLIKÃ“W ---
FILE_LIST_PROMPT = """
JesteÅ› Tech Leadem. Przeanalizuj plan architekta i wylistuj WSZYSTKIE pliki, ktÃ³re trzeba stworzyÄ‡.
ZwrÃ³Ä‡ TYLKO surowÄ… listÄ™ plikÃ³w w formacie JSON (lista stringÃ³w).
Nie dodawaj Å¼adnych komentarzy. Tylko JSON.

PrzykÅ‚ad:
["main.py", "requirements.txt", "src/utils.py"]

Plan Architekta:
{plan}
"""

# --- KROK 2: GENEROWANIE KODU DLA POJEDYNCZEGO PLIKU ---
CODE_GEN_PROMPT = """
JesteÅ› Senior Python Developerem.
Twoim zadaniem jest napisaÄ‡ zawartoÅ›Ä‡ pliku: "{filename}".

Kontekst projektu (Plan Architekta):
{plan}

WYMAGANIA:
1. ZwrÃ³Ä‡ TYLKO kod tego jednego pliku.
2. Nie uÅ¼ywaj markdowna (```python). Czysty tekst.
3. Kod musi byÄ‡ kompletny (z importami).

Napisz teraz kod dla: {filename}
"""

def extract_json_list(text):
    """Pomocnicza funkcja do wyciÄ…gania JSONa z odpowiedzi modelu"""
    try:
        # Szukamy czegoÅ› co wyglÄ…da jak lista ["..."]
        match = re.search(r'\[.*\]', text, re.DOTALL)
        if match:
            return json.loads(match.group())
        return json.loads(text)
    except:
        return []

def developer_node(state: ProjectState) -> ProjectState:
    tech_stack = state.get("tech_stack", "")
    
    # Sprawdzamy, czy to iteracja z poprawkami (QA)
    qa_feedback = state.get("qa_feedback", "")
    if qa_feedback:
        print(f"\nğŸ‘¨â€ğŸ’» Developer: WdziÄ™czam poprawki QA...")
        # Tutaj uproszczona logika dla poprawek - prosimy o poprawienie wszystkiego naraz
        # (W peÅ‚nej wersji moÅ¼na by teÅ¼ iterowaÄ‡, ale przy poprawkach kontekst jest kluczowy)
        # ... (zostawiamy starÄ… logikÄ™ dla poprawek lub po prostu nadpisujemy kluczowe pliki)
        pass 

    print(f"\nğŸ‘¨â€ğŸ’» Developer: AnalizujÄ™ listÄ™ plikÃ³w do utworzenia...")
    
    # 1. WyciÄ…gamy listÄ™ plikÃ³w
    prompt_files = ChatPromptTemplate.from_messages([
        ("system", FILE_LIST_PROMPT.format(plan=tech_stack))
    ])
    chain_files = prompt_files | llm
    response_files = chain_files.invoke({})
    
    files_to_create = extract_json_list(response_files.content)
    
    if not files_to_create:
        print("âš ï¸ Developer nie znalazÅ‚ plikÃ³w w planie. PrÃ³bujÄ™ zgadnÄ…Ä‡ main.py...")
        files_to_create = ["main.py"]

    print(f"ğŸ“‹ Lista zadaÅ„: {files_to_create}")
    
    generated_files = {}
    logs = []
    
    # 2. PÄ˜TLA GENEROWANIA (Plik po pliku)
    for filename in files_to_create:
        print(f"   ğŸ”¨ PiszÄ™ kod: {filename}...")
        
        prompt_code = ChatPromptTemplate.from_messages([
            ("system", CODE_GEN_PROMPT.format(filename=filename, plan=tech_stack))
        ])
        chain_code = prompt_code | llm
        response_code = chain_code.invoke({})
        
        # Czyszczenie kodu z ewentualnych znacznikÃ³w markdown
        code_content = response_code.content.replace("```python", "").replace("```", "").strip()
        
        # 3. Zapis na dysk (UÅ¼ywamy narzÄ™dzia bezpoÅ›rednio)
        save_msg = save_file.invoke({"filename": filename, "code_content": code_content})
        print(f"      ğŸ’¾ {save_msg}")
        
        generated_files[filename] = code_content
        logs.append(f"Utworzono: {filename}")

    return {
        "generated_code": generated_files,
        "logs": logs
    }